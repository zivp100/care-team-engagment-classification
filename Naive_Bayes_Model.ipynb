{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Care Team Engagment Prediction - Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook includes the following steps:\n",
    "<ul>\n",
    "<li> Setup\n",
    "<li> Read data file </li>\n",
    "<li> Process data file </li>\n",
    "<li> Remove nulls </li>\n",
    "<li> Define Y </li>\n",
    "<li> Split into train and test </li>\n",
    "<li> Predict using Naive Bayes Classifier </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read data file (locally or from S3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read local data file\n",
    "df1 = pd.read_csv('data5.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Reading a file from S3\n",
    "bucket='sagemaker-studio-02e2gyih7qot'\n",
    "data_key = 'Reviews.csv'\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "\n",
    "df1 = pd.read_csv(data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Process Input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53895, 30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['days_to_first_et', 'days_to_coach', 'indication', 'is_gender_female',\n",
       "       'is_gender_male', 'is_gender_other', 'bio_length', 'reasons_length',\n",
       "       'imagine_free_length', 'reason_limited_time',\n",
       "       'reason_family_obligations', 'reason_work_obligations', 'reason_other',\n",
       "       'surgery_1yr', 'pain_severity', 'pain_vas', 'pain_description_length',\n",
       "       'bmi', 'gad', 'phq', 'inbound_coach_messages_4_weeks',\n",
       "       'inbound_coach_messages_1_week', 'inbound_coach_messages_length_1_week',\n",
       "       'inbound_member_messages_4_weeks', 'inbound_member_messages_1_week',\n",
       "       'surgery_message', 'call_message', 'interaction_message',\n",
       "       'video_message', 'booking_message'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we have no member identification fields\n",
    "df1 = df1.drop(['pathway_id', 'user_id', 'uuid'], axis=1, errors='ignore') ## PHI Safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace indication with dummy variables\n",
    "indication_dummies = pd.get_dummies(df1['indication'])\n",
    "df1 = pd.concat([df1, indication_dummies], axis=1)      \n",
    "df1 = df1.drop(['indication'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all hot words into one column\n",
    "df1['hot_word'] =  df1['surgery_message'] + df1['call_message'] + df1['interaction_message'] + df1['video_message']\n",
    "\n",
    "# take out of the members that used a hot word. We know those should be assign to mid level\n",
    "hot_word_memebrs = df1[df1['hot_word'] > 0]\n",
    "df1 = df1[df1['hot_word'] == 0]\n",
    "df1 = df1.drop(['surgery_message', 'call_message', 'interaction_message', 'video_message', 'booking_message', 'hot_word'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Remove null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_to_first_et                            0\n",
      "days_to_coach                             987\n",
      "is_gender_female                            0\n",
      "is_gender_male                              0\n",
      "is_gender_other                             0\n",
      "bio_length                                  0\n",
      "reasons_length                              0\n",
      "imagine_free_length                         0\n",
      "reason_limited_time                         0\n",
      "reason_family_obligations                   0\n",
      "reason_work_obligations                     0\n",
      "reason_other                                0\n",
      "surgery_1yr                                 0\n",
      "pain_severity                           12177\n",
      "pain_vas                                 2099\n",
      "pain_description_length                     0\n",
      "bmi                                      2295\n",
      "gad                                         6\n",
      "phq                                         7\n",
      "inbound_coach_messages_4_weeks              0\n",
      "inbound_coach_messages_1_week               0\n",
      "inbound_coach_messages_length_1_week        0\n",
      "inbound_member_messages_4_weeks             0\n",
      "inbound_member_messages_1_week              0\n",
      "back                                        0\n",
      "hip                                         0\n",
      "knee                                        0\n",
      "neck                                        0\n",
      "shoulder                                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df1.isnull().sum()) # found no missing values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove members with transferred_to_coach_day = null\n",
    "df1 = df1[df1['days_to_coach'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if pain_severity or pain_vas is null -> 0\n",
    "df1['pain_severity'].fillna(0, inplace=True)\n",
    "df1['pain_vas'].fillna(0, inplace=True)\n",
    "df1['gad'].fillna(0, inplace=True)\n",
    "df1['phq'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but average BMI where BMI is null\n",
    "df1['bmi'].fillna((df1['bmi'].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_to_first_et                        0\n",
      "days_to_coach                           0\n",
      "is_gender_female                        0\n",
      "is_gender_male                          0\n",
      "is_gender_other                         0\n",
      "bio_length                              0\n",
      "reasons_length                          0\n",
      "imagine_free_length                     0\n",
      "reason_limited_time                     0\n",
      "reason_family_obligations               0\n",
      "reason_work_obligations                 0\n",
      "reason_other                            0\n",
      "surgery_1yr                             0\n",
      "pain_severity                           0\n",
      "pain_vas                                0\n",
      "pain_description_length                 0\n",
      "bmi                                     0\n",
      "gad                                     0\n",
      "phq                                     0\n",
      "inbound_coach_messages_4_weeks          0\n",
      "inbound_coach_messages_1_week           0\n",
      "inbound_coach_messages_length_1_week    0\n",
      "inbound_member_messages_4_weeks         0\n",
      "inbound_member_messages_1_week          0\n",
      "back                                    0\n",
      "hip                                     0\n",
      "knee                                    0\n",
      "neck                                    0\n",
      "shoulder                                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df1.isnull().sum()) # found no missing values in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Define Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 7\n",
    "\n",
    "# Define target column\n",
    "# See analysis below showed the 20% of customer = 9 or more messages\n",
    "df1['Y'] = df1['inbound_coach_messages_4_weeks'] > limit\n",
    "df1 = df1.drop(['inbound_member_messages_4_weeks', 'inbound_coach_messages_4_weeks'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    39638\n",
       "True     11997\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data for future use\n",
    "df1.to_csv('cleanData1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.iloc[:, 0:-1].values\n",
    "y = df1.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Predict using Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred  =  classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6245, 1718],\n",
       "       [1540,  824]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6845163164520189"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3241542092840283"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34856175972927245"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target is recall = 75% and precision = 65%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Naive Bayes classifiers</b> are fast and easy to implement but they assume the following: </BR> \n",
    "<ol>\n",
    "    <li> Features are independent </li>\n",
    "    <li> Features are Gaussian distributed </li>\n",
    "    <li> All features have the same weight </li>\n",
    "</ol>    \n",
    "In most of the real life cases, like in this case, this is not true.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-1:742091327244:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
